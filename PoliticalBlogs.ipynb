{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "from numpy import linalg\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "political=nx.read_gml(\"polblogs.gml\",label='id')\n",
    "\n",
    "#make the graph directed with no parallels\n",
    "political = nx.DiGraph(political)\n",
    "\n",
    "#returns a set of nodes of the biggest connected component\n",
    "largest = max(nx.connected_components(political.to_undirected()), key=len)\n",
    "\n",
    "# creates the graph of the biggest connected component including direction\n",
    "CC_max = political.subgraph(largest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_avg_score(G, node_id):\n",
    "    sum_of_score = 0\n",
    "    number_of_neighbors = 0\n",
    "    G=G.to_undirected()\n",
    "    for neighbor_id in G[node_id]:\n",
    "        sum_of_score += G.nodes[neighbor_id]['value']\n",
    "        number_of_neighbors += 1\n",
    "        \n",
    "    return sum_of_score / number_of_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(G):\n",
    "    next_scores = {}\n",
    "    for node_id in G.nodes():\n",
    "        if G.nodes[node_id]['value'] is 1 or G.nodes[node_id]['value'] is 0:\n",
    "            #if the node value is known it wont be changed\n",
    "            next_scores[node_id] = G.nodes[node_id]['value']\n",
    "        else:\n",
    "            next_scores[node_id] = calculate_avg_score(G, node_id)\n",
    "    return next_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now computing nodes for: 0.1\n",
      "========================\n"
     ]
    }
   ],
   "source": [
    "#Returns a list with the value of the nodes\n",
    "original_values = dict(CC_max.nodes(data='value', default=1))\n",
    "\n",
    "#get the b% of values\n",
    "percentage=0.1\n",
    "\n",
    "#a small value that stops the propagation\n",
    "convergence_factor = 0.00001\n",
    "\n",
    "#list that holds the values of every experiment\n",
    "precision_list = []\n",
    "\n",
    "for i in range(9):\n",
    "    \n",
    "    numbers_of_items_kept_from_percentage = round(len(a)*percentage)\n",
    "    sum_of_precision = 0\n",
    "    \n",
    "    print(\"Now computing nodes for:\",percentage)\n",
    "    print(\"========================\")\n",
    "    \n",
    "    for i in range(10):\n",
    "        \n",
    "        # shuffle the dictionary of values to get the random nodes\n",
    "        a1 = list(original_values.items())\n",
    "        np.random.shuffle(a1)\n",
    "        a = dict(a1)\n",
    "\n",
    "        #keep the first percentage b% of the nodes\n",
    "        nodes_kept = list(a.items())[:numbers_of_items_kept_from_percentage]\n",
    "\n",
    "\n",
    "        #holds the b% nodes with their original values, the rest of the nodes are initialized to 0.5\n",
    "        final_dictionary = a.copy()\n",
    "\n",
    "        #initialize not known node values\n",
    "        for key in dict(nodes_kept).keys():\n",
    "            final_dictionary[key] = 0.5\n",
    "\n",
    "        for key in final_dictionary.keys():\n",
    "            attrs = {key: {'value': final_dictionary[key]}}\n",
    "            nx.set_node_attributes(CC_max,attrs)\n",
    "\n",
    "\n",
    "        graph_to_be_propagated = CC_max.copy()\n",
    "\n",
    "\n",
    "        #for the first convergence comparison\n",
    "\n",
    "        previous_values = nx.get_node_attributes(CC_max,'value')\n",
    "        previous_values_for_comparison = list(previous_values.values())\n",
    "        norm_of_previous_values = linalg.norm(previous_values_for_comparison,1)\n",
    "\n",
    "        #propagate until convergence\n",
    "\n",
    "        while True:\n",
    "\n",
    "            next_values = propagate(graph_to_be_propagated)\n",
    "            list_of_next_values = list(next_values.values())\n",
    "            norm_of_next_values = linalg.norm(list_of_next_values,1)\n",
    "\n",
    "\n",
    "            norm_difference = abs(norm_of_next_values - norm_of_previous_values)\n",
    "\n",
    "            #print(norm_difference)\n",
    "\n",
    "            if norm_difference < convergence_factor:\n",
    "                break\n",
    "\n",
    "            #update the new values of the graph\n",
    "            for key in next_values.keys():\n",
    "                attrs = {key: {'value': next_values[key]}}\n",
    "                nx.set_node_attributes(graph_to_be_propagated,attrs)\n",
    "\n",
    "            #update the previous values\n",
    "            previous_values = copy.deepcopy(next_values)\n",
    "\n",
    "            #update the previous values norm for the next comparison\n",
    "            list_of_previous_values = list(previous_values.values())\n",
    "            norm_of_previous_values = linalg.norm(list_of_previous_values,1)\n",
    "\n",
    "\n",
    "        #predict the node values    \n",
    "        nodes = dict(graph_to_be_propagated.nodes(data='value', default=1))\n",
    "\n",
    "\n",
    "        #update the new values of the graph\n",
    "        for key in nodes.keys():\n",
    "            if nodes[key] > 0.5:\n",
    "                attrs = {key: {'value': 1}}\n",
    "            else:\n",
    "                attrs = {key: {'value': 0}}\n",
    "            nx.set_node_attributes(graph_to_be_propagated,attrs)\n",
    "\n",
    "\n",
    "        #Now compare original values with the values_after_propagation\n",
    "        \n",
    "        nodes = dict(graph_to_be_propagated.nodes(data='value', default=1))\n",
    "\n",
    "        shared_items = {k: nodes[k] for k in nodes if k in original_values and nodes[k] == original_values[k]}\n",
    "        \n",
    "        \n",
    "        # accuracy logic\n",
    "        #\n",
    "        # TP = no_of_shared_that_are_same - len(b%)\n",
    "        #\n",
    "        # FP = no_of_all_nodes - len(b%) - TP\n",
    "        # FP = no_of_all_nodes - len(b%) - no_of_shared_that_are_same + len(b%)\n",
    "        # FP = no_of_all_nodes - no_of_shared_that_are_same\n",
    "        \n",
    "        \n",
    "        true_positive = len(shared_items) - numbers_of_items_kept_from_percentage\n",
    "        \n",
    "        false_positive = len(original_values) - len(shared_items)\n",
    "        \n",
    "        precision = true_positive / (true_positive + false_positive)\n",
    "        \n",
    "        sum_of_precision += precision\n",
    "        \n",
    "    precision_results = sum_of_precision / 10\n",
    "    precision_list.append(precision_results)\n",
    "    \n",
    "    #update percentage\n",
    "    percentage += 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
