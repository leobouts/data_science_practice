{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "\n",
    "\n",
    "#load the traning data\n",
    "df = pd.read_csv('training_data.txt',names=['SPAM'])\n",
    "\n",
    "#create two columns, data are seperated with a tab.\n",
    "df[['SPAM','SMS']] = df[\"SPAM\"].str.split(\"\\t\", 1, expand=True)\n",
    "\n",
    "#keep only alphabetical characters\n",
    "df['SMS'] = df['SMS'].apply(lambda x : re.sub('[^a-z\\s]+',' ',x,flags=re.IGNORECASE)) \n",
    "\n",
    "#lowercase the string and replace multiple spaces with only one\n",
    "df['SMS'] = df['SMS'].apply(lambda x : re.sub('(\\s+)',' ',x.lower())) \n",
    "\n",
    "#remove stop-words\n",
    "stop = stopwords.words('english')\n",
    "df['SMS_without_stop_words'] = df['SMS'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "spam_dataframe = df[df['SPAM'] == 'True']\n",
    "\n",
    "non_spam_dataframe = df[df['SPAM'] == 'False']\n",
    "\n",
    "spam_bag_of_words = pd.Series([y for x in spam_dataframe['SMS'].values.flatten() for y in x.split()]).value_counts()\n",
    "\n",
    "non_spam_bag_of_words = pd.Series([y for x in non_spam_dataframe['SMS'].values.flatten() for y in x.split()]).value_counts()\n",
    "\n",
    "to_count = pd.Series([y for x in df['SMS'].values.flatten() for y in x.split()]).value_counts()\n",
    "\n",
    "count = to_count.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing spam messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = \"im totally not a spam string baby\"\n",
    "\n",
    "#load the test data\n",
    "test_dataframe = pd.read_csv('test_data.txt',names=['TEST'])\n",
    "\n",
    "#create two columns, data are seperated with a tab.\n",
    "test_dataframe[['example_number','SMS']] = test_dataframe[\"TEST\"].str.split(\"\\t\", 1, expand=True)\n",
    "\n",
    "#keep only alphabetical characters\n",
    "test_dataframe['SMS'] = test_dataframe['SMS'].apply(lambda x : re.sub('[^a-z\\s]+',' ',x,flags=re.IGNORECASE)) \n",
    "\n",
    "#lowercase the string and replace multiple spaces with only one\n",
    "test_dataframe['SMS'] = test_dataframe['SMS'].apply(lambda x : re.sub('(\\s+)',' ',x.lower()))\n",
    "\n",
    "#get the number of training examples by getting the rows of the spam or non spam dataframe\n",
    "\n",
    "total_trained_examples = spam_dataframe.shape[0] + non_spam_dataframe.shape[0]\n",
    "\n",
    "\n",
    "spam_probability = spam_dataframe.shape[0] / total_trained_examples\n",
    "\n",
    "non_spam_probability = non_spam_dataframe.shape[0] / total_trained_examples\n",
    "\n",
    "with open('results.csv', 'w', newline='') as file:\n",
    "    \n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    #add header\n",
    "    writer.writerow(['id', 'label'])\n",
    "    \n",
    "    for index, row in test_dataframe.iterrows():\n",
    "        \n",
    "        test_string = row['SMS']\n",
    "        \n",
    "        filtered_words = list(filter(lambda word: word not in stop, test_string.split()))\n",
    "        \n",
    "    \n",
    "        product_spam = 1\n",
    "\n",
    "        product_non_spam = 1\n",
    "        \n",
    "        word_count = len(test_string.split())\n",
    "\n",
    "\n",
    "        #find times the word is found in each category\n",
    "        for word in test_string.split():\n",
    "\n",
    "            #if the word is not found on the training set set the nontype to 0\n",
    "\n",
    "            times_word_found_in_spam = int(spam_bag_of_words.get(key = word) or 0)\n",
    "            times_word_found_in_non_spam = int(non_spam_bag_of_words.get(key = word) or 0)\n",
    "\n",
    "            spam_word_probability = (times_word_found_in_spam + 1) / (spam_bag_of_words.sum() + count + 1)\n",
    "\n",
    "            non_spam_word_probability = (times_word_found_in_non_spam + 1) / (non_spam_bag_of_words.sum() + count + 1)\n",
    "\n",
    "            product_spam = spam_word_probability * product_spam\n",
    "            product_non_spam = non_spam_word_probability * product_non_spam\n",
    "\n",
    "\n",
    "        spam = product_spam*spam_probability\n",
    "        non_spam = product_non_spam*non_spam_probability\n",
    "\n",
    "        if(spam > non_spam):\n",
    "            writer.writerow([row['example_number'], \"True\"])\n",
    "        else:\n",
    "            writer.writerow([row['example_number'], \"False\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
