{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import feature_extraction\n",
    "from heapq import nlargest\n",
    "from functools import reduce\n",
    "from operator import add\n",
    "from numpy import array\n",
    "from scipy.linalg import svd\n",
    "import copy\n",
    "import scipy.spatial.distance as dist\n",
    "import heapq\n",
    "import random\n",
    "import numpy\n",
    "import time\n",
    "import string\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returns a list of 1000 recipes with one random ingredient deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data():\n",
    "    global recipes_before_removing_element\n",
    "    \n",
    "    \n",
    "    f = open('train.json')\n",
    "    data = json.load(f)\n",
    "\n",
    "    recipe_list = []\n",
    "\n",
    "    for i in data:\n",
    "        #split with comma to get the cuisine.\n",
    "        split1=str(i).split(',')\n",
    "        #clean the strings with split and regex\n",
    "        split2 = split1[1].split(':')\n",
    "        cuisine = re.sub(r'[.\\W]','',split2[1])\n",
    "        #get the recipe id\n",
    "        recipe_split = split1[0].split(': ')\n",
    "        recipe_id=recipe_split[1]\n",
    "        #keep only the pepperoni guys\n",
    "        if cuisine=='italian':\n",
    "            #splitting with [ because ingredients have the only list in the string\n",
    "            split3=str(i).split('[')\n",
    "            #final cut\n",
    "            ingredients=split3[1].split(',')\n",
    "            #removing ' from the strings\n",
    "            ingredients = [s.translate(str.maketrans('','',string.punctuation)) for s in ingredients]\n",
    "            if len(ingredients)>2:\n",
    "                recipe_list.append(ingredients)\n",
    "            \n",
    "    #randomize the recipes\n",
    "    random.shuffle(recipe_list)\n",
    "    #get the first 1000 randomized items\n",
    "    set_of_recipes = recipe_list[:1000]\n",
    "\n",
    "    #remove whitespaces\n",
    "    for i,obj in enumerate(set_of_recipes):\n",
    "        set_of_recipes[i] = [x.strip() for x in set_of_recipes[i]]\n",
    "    \n",
    "    recipes_before_removing_element = copy.deepcopy(set_of_recipes)\n",
    "\n",
    "    \n",
    "    #remove 1 random ingredient from every recipes\n",
    "    for i,obj in enumerate(set_of_recipes):\n",
    "        #randomise the list and remove the first element\n",
    "        random.shuffle(set_of_recipes[i])\n",
    "        set_of_recipes[i].pop(0)        \n",
    "\n",
    "    return set_of_recipes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computes Jaccard similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(list1, list2):\n",
    "    set1, set2 = set(list1), set(list2)\n",
    "    # Jaccard = Intersection(set1,set2) / Union(set1,set2)\n",
    "    if len(set1 | set2) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(set1 & set2) / len(set1 | set2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returns the binary matrix of the recipes-ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectorized_matrix():\n",
    "    matrix =[]\n",
    "    for i,obj in enumerate(recipes):\n",
    "        vector = [0] * len(unique_ingredients)\n",
    "        current_recipe = recipes[i]\n",
    "        for j,obj in enumerate(current_recipe):\n",
    "            if current_recipe[j] in unique_ingredients:\n",
    "                vector[unique_ingredients.tolist().index(current_recipe[j])] = 1\n",
    "        matrix.append(vector)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returns the most popular score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_popular_score():\n",
    "    # Popular_without_recipes_ingredients is a dict but without the ingredients \n",
    "    # of the current recipe of the loop.\n",
    "    score_list = []\n",
    "    #popular is a dictionary with : (ingredient,times igredient used in all the recipes)\n",
    "    popular = dict((x,flattened_recipes_set.count(x)) for x in set(flattened_recipes_set))\n",
    "    for i in recipes:\n",
    "        popular_without_recipes_ingredients = list(filter(lambda x: x in i, popular)) \n",
    "        score_list.append(popular_without_recipes_ingredients)\n",
    "    return score_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returns a matrix with all the Jaccard similarities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jaccard_matrix():\n",
    "    matrix=[]\n",
    "    for elem1 in recipes:\n",
    "        #list with the jaccard of the recipe elem1 with every other\n",
    "        jaccard_of_recipe = []\n",
    "        for elem2 in recipes:\n",
    "            jaccard_of_recipe.append(jaccard_similarity(elem1,elem2))\n",
    "        matrix.append(jaccard_of_recipe)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returns a matrix with all the Jaccard similarities of the ingredients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jaccard_matrix_ingredients():\n",
    "    matrix=[]\n",
    "    for i in unique_ingredients:\n",
    "        jaccard_of_ingredients = []\n",
    "        for j in unique_ingredients:\n",
    "            jaccard_of_ingredients.append(jaccard_similarity(list(i),list(j)))\n",
    "        matrix.append(jaccard_of_ingredients)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returns the n most similar for every recipe or ingredient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_similar_indexes(n,length,jaccard_matrix):\n",
    "    similar = []\n",
    "    for i in range(length):\n",
    "        a = numpy.array(jaccard_matrix[i])\n",
    "        #the Jaccard similarity of an item with itself is always 1.\n",
    "        #we are going to get the n+1 largest values so we can pop out\n",
    "        #the one with itself.\n",
    "\n",
    "        #gives the indexes of the n+1 largest values og jaccard\n",
    "        most_similar = heapq.nlargest(n+1, range(len(a)), a.take)\n",
    "\n",
    "        #remove the most similar(itself)\n",
    "        most_similar.pop(0)\n",
    "        similar.append(most_similar)\n",
    "\n",
    "    return similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returns the Jaccard similarity of the n most similar recipes for every recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_similar_values(n,length,jaccard_matrix):\n",
    "    values = []\n",
    "    for i in range(length):\n",
    "        #gives the values of jaccard of the n+1 largest values\n",
    "        jaccard = heapq.nlargest(n+1, jaccard_matrix[i])\n",
    "        #remove the most similar(itself)\n",
    "        jaccard.pop(0)\n",
    "        values.append(jaccard)\n",
    "\n",
    "    return values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computes the UCF score of n similar recipes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_based_collaborative_filtering(n,matrix,unique):\n",
    "    scores = []\n",
    "    for i,obj in enumerate(recipes):\n",
    "        scores_1=[]\n",
    "        ingredients_without_recipe_ingredients = list(set(unique) - set(recipes[i]))\n",
    "        for j in ingredients_without_recipe_ingredients:\n",
    "            jaccard_dot_matrix_sum = 0\n",
    "            jaccard_sum = 0\n",
    "            index_of_ingredient = unique.tolist().index(j)\n",
    "            for k in range(n):\n",
    "                m = set_of_n_similar_recipes[i][k]\n",
    "                jaccard_dot_matrix_sum += most_similar_jaccard_values[i][k] * matrix[m][index_of_ingredient]\n",
    "                jaccard_sum += most_similar_jaccard_values[i][k]\n",
    "            if jaccard_sum != 0:    \n",
    "                scores_1.append(jaccard_dot_matrix_sum/jaccard_sum)\n",
    "            else:\n",
    "                scores_1.append(0)        \n",
    "        scores.append(scores_1)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computes the ICF score of n similar ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_based_collaborative_filtering(n,matrix,unique):\n",
    "    scores = []\n",
    "    for i,obj in enumerate(recipes):\n",
    "        scores_1=[]\n",
    "        ingredients_without_current = list(set(unique) - set(recipes[i]))\n",
    "        for j,obj in enumerate(ingredients_without_current):\n",
    "            index_of_ingredient = unique.tolist().index(ingredients_without_current[j])\n",
    "            jaccard_dot_matrix_sum = 0\n",
    "            jaccard_sum = 0\n",
    "            for k in range(n):\n",
    "                m = set_of_n_similar_ingredients[index_of_ingredient][k]\n",
    "                jaccard_dot_matrix_sum += most_similar_jaccard_values_ingredients[index_of_ingredient][k] * matrix[i][m]\n",
    "                jaccard_sum += most_similar_jaccard_values_ingredients[index_of_ingredient][k]\n",
    "            if jaccard_sum != 0:    \n",
    "                scores_1.append(jaccard_dot_matrix_sum/jaccard_sum)\n",
    "            else:\n",
    "                scores_1.append(0)  \n",
    "        scores.append(scores_1)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_recipes: row x lengths\n",
      "1000\n",
      "x\n",
      "1000\n",
      "--------------------\n",
      "distance_ingredients: row x lengths\n",
      "1249\n",
      "x\n",
      "1249\n"
     ]
    }
   ],
   "source": [
    "global most_similar_jaccard_values\n",
    "global set_of_n_similar_recipes\n",
    "global recipes\n",
    "global unique_ingredients\n",
    "global flattened_recipes_set\n",
    "global scores\n",
    "global recipes_before_removing_element\n",
    "global set_of_recipes\n",
    "\n",
    "\n",
    "recipes = clean_data()\n",
    "\n",
    "#make the 2d list 1d so we can count occurences easily\n",
    "flattened_recipes_set = copy.deepcopy(recipes)\n",
    "flattened_recipes_set = reduce(lambda x,y :x+y ,flattened_recipes_set)\n",
    "\n",
    "#remove whitespaces\n",
    "#flattened_recipes_set = [x.strip() for x in flattened_recipes_set]\n",
    "\n",
    "#find the unique ingredients list\n",
    "numpy_of_flattened = numpy.array(flattened_recipes_set)\n",
    "unique_ingredients = numpy.unique(numpy_of_flattened)\n",
    "\n",
    "#Create Vectorized Matrix\n",
    "vectorized_matrix_m = create_vectorized_matrix()\n",
    "\n",
    "#list that holds every score for every ingredient.\n",
    "#every line i of the array corresponds to the score\n",
    "#the ingredients have for the recipe in line i of the recipes array.\n",
    "most_popular_score_list = most_popular_score()\n",
    "\n",
    "\n",
    "distance_recipes = compute_jaccard_matrix()\n",
    "distance_ingredients = compute_jaccard_matrix_ingredients()\n",
    "\n",
    "print(\"distance_recipes: row x lengths\")\n",
    "print(len(distance_recipes))\n",
    "print(\"x\")\n",
    "print(len(distance_recipes[0]))\n",
    "print('--------------------')\n",
    "print(\"distance_ingredients: row x lengths\")\n",
    "print(len(distance_ingredients))\n",
    "print(\"x\")\n",
    "print(len(distance_ingredients[1]))\n",
    "\n",
    "\n",
    "#distance array now has in line i the jacard similarity of\n",
    "#the recipe of line i in the recipes set with every other recipe\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCF Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now computing for n=: 25\n",
      "1000\n",
      "1243\n",
      "now computing for n=: 50\n",
      "1000\n",
      "1243\n",
      "now computing for n=: 75\n",
      "1000\n",
      "1243\n",
      "now computing for n=: 100\n",
      "1000\n",
      "1243\n"
     ]
    }
   ],
   "source": [
    "#set_of_n_similar_recipes has in each line i the n most similar recipes\n",
    "#for the recipe in line i of the recipes array according to the jaccard metric\n",
    "\n",
    "list_of_lists_of_scores_for_every_n_ucf = []\n",
    "recipes_length = len(recipes)\n",
    "\n",
    "##for testing\n",
    "list_of_lists_of_most_similar_recipes_for_every_n_ucf = []\n",
    "list_of_lists_of_most_similar_jaccard_values_for_every_n_ucf = []\n",
    "\n",
    "\n",
    "for i in range(25, 101, 25):\n",
    "    print(\"now computing for n=:\",i)\n",
    "    set_of_n_similar_recipes = get_n_similar_indexes(i,recipes_length,distance_recipes)\n",
    "    most_similar_jaccard_values = get_n_similar_values(i,recipes_length,distance_recipes)\n",
    "    ucf_scores = user_based_collaborative_filtering(i,vectorized_matrix_m,unique_ingredients)\n",
    "    print(len(ucf_scores))\n",
    "    print(len(ucf_scores[1]))\n",
    "\n",
    "    ##for testing\n",
    "    list_of_lists_of_most_similar_recipes_for_every_n_ucf.append(set_of_n_similar_recipes)\n",
    "    list_of_lists_of_most_similar_jaccard_values_for_every_n_ucf.append(most_similar_jaccard_values)\n",
    "    ##\n",
    "    \n",
    "    list_of_lists_of_scores_for_every_n_ucf.append(ucf_scores)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recipe before removing:\n",
      "['chopped fresh sage', 'cracked black pepper', 'fresh oregano', 'fresh parsley', 'noodles', 'olive oil', 'parmigiano reggiano cheese', 'partskim ricotta cheese', 'pinenuts', 'salt', 'unsalted butter']\n",
      "recipe:\n",
      "['chopped fresh sage', 'cracked black pepper', 'fresh oregano', 'fresh parsley', 'noodles', 'olive oil', 'parmigiano reggiano cheese', 'partskim ricotta cheese', 'pinenuts', 'unsalted butter']\n",
      "================\n",
      "['salt']\n",
      "algorithm found:\n",
      "loin pork roast\n"
     ]
    }
   ],
   "source": [
    "# print(\"a random recipe with values to test if the jaccard is correct\")\n",
    "# print(\"88th recipe:\")\n",
    "# print(sorted(recipes[88]))\n",
    "# print('================')\n",
    "# print(\"Jaccard of second recipe with 88th recipe\")\n",
    "# print(distance_recipes[1][88])\n",
    "# print('================')\n",
    "a = list_of_lists_of_most_similar_jaccard_values_for_every_n_ucf[1]\n",
    "b = list_of_lists_of_most_similar_recipes_for_every_n_ucf[1]\n",
    "# #print(len(a))\n",
    "# #print(len(b))\n",
    "# print(\"5 most similar recipes(indexes) of the 2th recipe\")\n",
    "# print(b[1])\n",
    "# print(\"5 most similar jaccard values of the 2th recipe between these:\")\n",
    "# print(a[1])\n",
    "# print(\"================\")\n",
    "# # for i in b[0]:\n",
    "# #     print(i)\n",
    "# #     print(recipes[i])\n",
    "# #     print('%%%%%%%%%%%')\n",
    "# print(\"=================\")\n",
    "# sum_of_jaccard = sum(a[1])\n",
    "# print(\"sum of 5 most similar jaccard values of the 0th recipe between these:\")\n",
    "# print(sum_of_jaccard)\n",
    "# print(\"=================\")\n",
    "\n",
    "\n",
    "\n",
    "test_recipe_number = 345\n",
    "\n",
    "# print(\"binary matrix values\")\n",
    "# print(\"M[r',i]\")\n",
    "# for i in b[1]:\n",
    "#     print(\"-----------------\")\n",
    "#     print(recipes[i])\n",
    "#     print(\"-----------------\")\n",
    "#     for j in sorted(sorted(recipes[test_recipe_number])):\n",
    "#         print(\"M[\",i,\",\",j,\"]\",vectorized_matrix_m[i][unique_ingredients.tolist().index(j)])\n",
    "#     print(\"=================\")\n",
    "\n",
    "print(\"recipe before removing:\")\n",
    "print(sorted(recipes_before_removing_element[test_recipe_number]))\n",
    "print(\"recipe:\")\n",
    "print(sorted(recipes[test_recipe_number]))\n",
    "print('================')\n",
    "hidden_element = list(set(recipes_before_removing_element[test_recipe_number]) - set(recipes[test_recipe_number]))\n",
    "print(hidden_element)\n",
    "print(\"algorithm found:\")\n",
    "#print(\"UCF scores for:\")\n",
    "#print(len(list_of_lists_of_scores_for_every_n_ucf[1][test_recipe_number]))\n",
    "max_value = max(list_of_lists_of_scores_for_every_n_ucf[1][test_recipe_number])\n",
    "max_index = list_of_lists_of_scores_for_every_n_ucf[1][test_recipe_number].index(max_value)\n",
    "print(unique_ingredients[max_index])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICF Scoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now computing ICF for N= 25\n",
      "Now computing ICF for N= 50\n",
      "Now computing ICF for N= 75\n",
      "Now computing ICF for N= 100\n"
     ]
    }
   ],
   "source": [
    "ingredients_length = len(unique_ingredients)\n",
    "list_of_lists_of_scores_for_every_n_icf = []\n",
    "\n",
    "for i in range(25, 101, 25):\n",
    "    print(\"Now computing ICF for N=\",i)\n",
    "    set_of_n_similar_ingredients = get_n_similar_indexes(i,ingredients_length,distance_ingredients)\n",
    "    most_similar_jaccard_values_ingredients = get_n_similar_values(i,ingredients_length,distance_ingredients)\n",
    "\n",
    "    icf_scores = item_based_collaborative_filtering(i,vectorized_matrix_m,unique_ingredients)\n",
    "    list_of_lists_of_scores_for_every_n_icf.append(icf_scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lists_of_scores_for_every_n_svd_U = []\n",
    "list_of_lists_of_scores_for_every_n_svd_s = []\n",
    "list_of_lists_of_scores_for_every_n_svd_VT = []\n",
    "\n",
    "for i in range(25, 101, 25):\n",
    "    U, s, VT = svd(vectorized_matrix_m)\n",
    "    list_of_lists_of_scores_for_every_n_svd_U.append(U)\n",
    "    list_of_lists_of_scores_for_every_n_svd_s.append(s)\n",
    "    list_of_lists_of_scores_for_every_n_svd_VT.append(VT)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision ucf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0\n",
      "precision: 0.0\n",
      "iteration: 1\n",
      "precision: 0.0\n",
      "iteration: 2\n",
      "precision: 0.0\n",
      "iteration: 3\n",
      "precision: 0.0\n",
      "[0.0]\n",
      "Best precision for ucf is computed by: 25\n"
     ]
    }
   ],
   "source": [
    "for i,obj in enumerate(list_of_lists_of_scores_for_every_n_ucf):\n",
    "    found_sum = 0\n",
    "    scores = list_of_lists_of_scores_for_every_n_ucf[i]\n",
    "    precisions_ucf = []\n",
    "    \n",
    "    for j,obj in enumerate(recipes):\n",
    "        hidden_element = list(set(recipes_before_removing_element[j]) - set(recipes[j]))\n",
    "        #print(hidden_element)\n",
    "        #for K=1 we just want the maximum value\n",
    "        max_value = max(scores[j])\n",
    "        max_index = scores[j].index(max_value)\n",
    "        \n",
    "        ingredient_proposed_by_the_algorithm = unique_ingredients[max_index]\n",
    "\n",
    "        if ingredient_proposed_by_the_algorithm == hidden_element[0]:\n",
    "            found_sum += 1\n",
    "            \n",
    "    print(\"iteration:\",i)\n",
    "    print(\"precision:\",found_sum/len(recipes))\n",
    "    precisions_ucf.append(found_sum/len(recipes))\n",
    "\n",
    "    \n",
    "max_value_precisions_ucf = max(precisions_ucf)\n",
    "max_index_precisions_ucf = precisions_ucf.index(max_value_precisions_ucf)\n",
    "\n",
    "print(precisions_ucf)\n",
    "\n",
    "best_n_value_ucf = max_index_precisions_ucf*25 +25\n",
    "\n",
    "print(\"Best precision for ucf is computed by:\", best_n_value_ucf)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision Icf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0\n",
      "precision: 0.001\n",
      "iteration: 1\n",
      "precision: 0.001\n",
      "iteration: 2\n",
      "precision: 0.0\n",
      "iteration: 3\n",
      "precision: 0.001\n",
      "Best precision for icf is computed by N: 25\n"
     ]
    }
   ],
   "source": [
    "for i,obj in enumerate(list_of_lists_of_scores_for_every_n_icf):\n",
    "    found_sum = 0\n",
    "    scores = list_of_lists_of_scores_for_every_n_icf[i]\n",
    "    precisions_icf = []\n",
    "    \n",
    "    for j,obj in enumerate(recipes):\n",
    "    \n",
    "        hidden_element = list(set(recipes_before_removing_element[j]) - set(recipes[j]))\n",
    "        \n",
    "        #for K=1 we just want the maximum value\n",
    "        max_value = max(scores[j])\n",
    "        max_index = scores[j].index(max_value)\n",
    "        \n",
    "        ingredient_proposed_by_the_algorithm = unique_ingredients[max_index]\n",
    "        \n",
    "        if ingredient_proposed_by_the_algorithm == hidden_element[0]:\n",
    "            found_sum += 1\n",
    "            \n",
    "    print(\"iteration:\",i)\n",
    "    print(\"precision:\",found_sum/len(recipes))\n",
    "    precisions_icf.append(found_sum/len(recipes))\n",
    "\n",
    "\n",
    "max_value_precisions_icf = max(precisions_icf)\n",
    "max_index_precisions_icf = precisions_icf.index(max_value_precisions_icf)\n",
    "\n",
    "best_n_value_icf = max_index_precisions_icf*25 +25\n",
    "\n",
    "print(\"Best precision for icf is computed by N:\", best_n_value_icf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
